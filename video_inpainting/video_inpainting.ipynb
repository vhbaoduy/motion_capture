{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "y6a28hS6rw_j",
        "zSHUUsJipeXb",
        "Bo8RN6UdydXH",
        "-ty3jw58yhuI",
        "AreD_PL7yms4",
        "zZurXfq-F6jj",
        "gDNKrW-NipaV",
        "Chnqa6pFrNN6",
        "lv4fnTdaWe9K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Human-Segmentation\n"
      ],
      "metadata": {
        "id": "y6a28hS6rw_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment"
      ],
      "metadata": {
        "id": "zSHUUsJipeXb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6y5PqbOprr6",
        "outputId": "dfd3093b-b57c-448f-8835-6b5dfa6192e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install iglovikov_helper_functions\n",
        "!pip install people_segmentation  > /dev/null"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting iglovikov_helper_functions\n",
            "  Downloading iglovikov_helper_functions-0.0.53-py2.py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (2.4.0)\n",
            "Collecting imagecorruptions (from iglovikov_helper_functions)\n",
            "  Downloading imagecorruptions-1.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.3.2)\n",
            "Collecting jpeg4py (from iglovikov_helper_functions)\n",
            "  Downloading jpeg4py-0.1.4.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (4.8.0.76)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (1.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from iglovikov_helper_functions) (2.0.1+cu118)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (2.31.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (2023.8.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->iglovikov_helper_functions) (23.1)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from jpeg4py->iglovikov_helper_functions) (1.15.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->iglovikov_helper_functions) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->iglovikov_helper_functions) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->iglovikov_helper_functions) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->iglovikov_helper_functions) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iglovikov_helper_functions) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iglovikov_helper_functions) (16.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->iglovikov_helper_functions) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->jpeg4py->iglovikov_helper_functions) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->iglovikov_helper_functions) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->iglovikov_helper_functions) (1.3.0)\n",
            "Building wheels for collected packages: jpeg4py\n",
            "  Building wheel for jpeg4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jpeg4py: filename=jpeg4py-0.1.4-py3-none-any.whl size=8423 sha256=164afb447e1db3ed3f708dfc80330aa2029ca4ec4dda62d8b0e8a2e0cfb5a883\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c3/0f/348e6cadb3a27435e833d21d91707d653fb159d69f2a867a36\n",
            "Successfully built jpeg4py\n",
            "Installing collected packages: jpeg4py, imagecorruptions, iglovikov_helper_functions\n",
            "Successfully installed iglovikov_helper_functions-0.0.53 imagecorruptions-1.1.2 jpeg4py-0.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPfDG7jKz1FF"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from pylab import imshow\n",
        "import torch\n",
        "import albumentations as albu\n",
        "\n",
        "from iglovikov_helper_functions.utils.image_utils import load_rgb, pad, unpad\n",
        "from iglovikov_helper_functions.dl.pytorch.utils import tensor_from_rgb_image\n",
        "\n",
        "from people_segmentation.pre_trained_models import create_model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup model\n"
      ],
      "metadata": {
        "id": "Bo8RN6UdydXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = albu.Compose([albu.Normalize(p=1)], p=1)"
      ],
      "metadata": {
        "id": "u6uQ8lhdzESZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(\"Unet_2020-07-20\")\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "Gv1ogg4vyfx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300e49c6-2deb-424f-e1fd-656cdcb08d1b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ternaus/people_segmentation/releases/download/0.0.1/2020-09-23a.zip\" to /root/.cache/torch/hub/checkpoints/2020-09-23a.zip\n",
            "100%|██████████| 47.0M/47.0M [00:02<00:00, 17.6MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:665: UserWarning: Falling back to the old format < 1.6. This support will be deprecated in favor of default zipfile format introduced in 1.6. Please redo torch.save() to save it in the new zipfile format.\n",
            "  warnings.warn('Falling back to the old format < 1.6. This support will be '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process video"
      ],
      "metadata": {
        "id": "-ty3jw58yhuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35e8sy7Ap8xz",
        "outputId": "972504ee-73d3-4e05-d88a-77cf4cbea207"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1Vrh8ucwZ7QAdUicHspAW2_lV_dOekKS0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqNQorrpp4Jo",
        "outputId": "6e581d7b-54f5-48b6-c779-23cab7a85362"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Vrh8ucwZ7QAdUicHspAW2_lV_dOekKS0\n",
            "To: /content/video.mp4\n",
            "\r  0% 0.00/1.02M [00:00<?, ?B/s]\r100% 1.02M/1.02M [00:00<00:00, 141MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf frames_origin"
      ],
      "metadata": {
        "id": "CpSTOe7U3lo4"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "video_path = 'video.mp4'\n",
        "output_folder = 'frames_origin'\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_rate = 38  # Desired frame rate in frames per second\n",
        "frame_interval = 1.0 / frame_rate\n",
        "\n",
        "frame_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    current_time = time.time()\n",
        "    elapsed_time = current_time - start_time\n",
        "\n",
        "    # Check if it's time to capture the next frame\n",
        "    if elapsed_time >= frame_interval:\n",
        "        frame_count += 1\n",
        "        count = str(frame_count)\n",
        "        if len(count) < 2:\n",
        "          count = '0' + count\n",
        "        frame_filename = os.path.join(output_folder, f'frame_{count}.jpg')\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "        start_time = current_time\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "j37uTKqQxVVQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create mask"
      ],
      "metadata": {
        "id": "AreD_PL7yms4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVC7JJyw0VSe"
      },
      "source": [
        "origin_path = 'frames_origin/'\n",
        "\n",
        "mask_path = 'frames_mask/'\n",
        "os.makedirs(mask_path, exist_ok=True)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OByo1iaAwJD"
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "  for dirpath, dirnames, filenames in os.walk(origin_path):\n",
        "    if not dirnames:\n",
        "      for file in filenames:\n",
        "        image = load_rgb(dirpath + file)\n",
        "\n",
        "        padded_image, pads = pad(image, factor=32, border=cv2.BORDER_CONSTANT)\n",
        "        x = transform(image=padded_image)[\"image\"]\n",
        "        x = torch.unsqueeze(tensor_from_rgb_image(x), 0)\n",
        "        x = x.to(device)\n",
        "\n",
        "        prediction = model(x)[0][0]\n",
        "        mask = (prediction > 0).cpu().numpy().astype(np.uint8) * 255\n",
        "        mask = unpad(mask, pads)\n",
        "\n",
        "        cv2.imwrite(mask_path + file, mask)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video-Inpainting"
      ],
      "metadata": {
        "id": "zZurXfq-F6jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment"
      ],
      "metadata": {
        "id": "gDNKrW-NipaV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4nBXDYiE-Y9",
        "outputId": "235e4393-bf3e-44f4-e214-1f2769ad797d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.7.1.tar.gz (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.4/605.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (6.0.1)\n",
            "Collecting yapf (from mmcv-full)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.16.2)\n",
            "Building wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.7.1-cp310-cp310-linux_x86_64.whl size=30392885 sha256=07ef89ccb5cf5c2582cf8baeccb2ad61b5bc03c26583c2f401ede721df11e57c\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/9a/65/470be18e21a8f2d085a024f0731508273543de0b5f79d9ddd4\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: addict, yapf, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.7.1 yapf-0.40.1\n"
          ]
        }
      ],
      "source": [
        "# Install MMCV\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/KhaLee2307/video-inpainting.git"
      ],
      "metadata": {
        "id": "L-PIeyiG1vDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a854ffbc-7881-4100-85f5-1d8bb3efef6a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'video-inpainting'...\n",
            "remote: Enumerating objects: 345, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 345 (delta 48), reused 32 (delta 32), pack-reused 268\u001b[K\n",
            "Receiving objects: 100% (345/345), 36.75 MiB | 12.11 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup model"
      ],
      "metadata": {
        "id": "Chnqa6pFrNN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd video-inpainting/release_model\n",
        "!gdown 1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\n",
        "!unzip E2FGVI_CVPR22_models.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkTu5gl0rMpy",
        "outputId": "c417bc2c-b9e4-4f81-993d-d283765df4ad"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video-inpainting/release_model\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\n",
            "To: /content/video-inpainting/release_model/E2FGVI_CVPR22_models.zip\n",
            "100% 202M/202M [00:00<00:00, 225MB/s]\n",
            "Archive:  E2FGVI_CVPR22_models.zip\n",
            "  inflating: E2FGVI-CVPR22.pth       \n",
            "  inflating: i3d_rgb_imagenet.pt     \n",
            "/content/video-inpainting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference\n"
      ],
      "metadata": {
        "id": "lv4fnTdaWe9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd video-inpainting\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iStJ_wz2wgOb",
        "outputId": "44ae0a01-97a2-4add-c5cd-bcb2aba7400d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video-inpainting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py --model e2fgvi --video /content/frames_origin --mask /content/frames_mask --ckpt release_model/E2FGVI-CVPR22.pth --savefps 10 --neighbor_stride 5"
      ],
      "metadata": {
        "id": "aXPgvlRvF7oc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44230c00-f28b-44cb-b5a1-4aa89c614a56"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n",
            "load pretrained SPyNet...\n",
            "load checkpoint from http path: https://download.openmmlab.com/mmediting/restorers/basicvsr/spynet_20210409-c6c1bd09.pth\n",
            "Loading model from: release_model/E2FGVI-CVPR22.pth\n",
            "Loading videos and masks from: /content/frames_origin | INPUT MP4 format: False\n",
            "Start test...\n",
            "  0% 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "100% 18/18 [00:28<00:00,  1.59s/it]\n",
            "Saving videos...\n",
            "Finish test! The result video is saved in: results/frames_origin_results.mp4.\n",
            "Let us enjoy the result!\n",
            "Figure(640x480)\n",
            "/usr/local/lib/python3.10/dist-packages/matplotlib/animation.py:884: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}